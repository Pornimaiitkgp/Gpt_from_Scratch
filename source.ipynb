{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bac17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: [' ', 'd', 'e', 'h', 'l', 'o', 'r', 'w']\n",
      "\n",
      "Character to Integer mapping:\n",
      "{' ': 0, 'd': 1, 'e': 2, 'h': 3, 'l': 4, 'o': 5, 'r': 6, 'w': 7}\n",
      "\n",
      "Encoded sequence: [3, 2, 4, 4, 5, 0, 7, 5, 6, 4, 1]\n",
      "\n",
      "Decoded text: hello world\n"
     ]
    }
   ],
   "source": [
    "# Character level tokenisation\n",
    "\n",
    "# Step 1: Input text\n",
    "text = \"hello world\"\n",
    "\n",
    "# Step 2: Get all unique characters in the text\n",
    "vocab = sorted(list(set(text)))\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "# Step 3: Create mappings: char → int and int → char\n",
    "char_to_int = {ch: i for i, ch in enumerate(vocab)}\n",
    "int_to_char = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "print(\"\\nCharacter to Integer mapping:\")\n",
    "print(char_to_int)\n",
    "\n",
    "# Step 4: Encode (text → integers)\n",
    "encoded = [char_to_int[ch] for ch in text]\n",
    "print(\"\\nEncoded sequence:\", encoded)\n",
    "\n",
    "# Step 5: Decode (integers → text)\n",
    "decoded = ''.join([int_to_char[i] for i in encoded])\n",
    "print(\"\\nDecoded text:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0705dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram count matrix:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0]], dtype=torch.int32)\n",
      "\n",
      "Probability matrix:\n",
      " tensor([[0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.2222],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.2222, 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.2222, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],\n",
      "        [0.0909, 0.1818, 0.0909, 0.0909, 0.1818, 0.1818, 0.0909, 0.0909],\n",
      "        [0.2000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.1000],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.2222, 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.2222, 0.1111, 0.1111]])\n",
      "\n",
      "Generated text: elredeloo lrdwrrwd  w\n"
     ]
    }
   ],
   "source": [
    "# Bigram Model\n",
    "\n",
    "# Count bigrams (pairs of consecutive chars)\n",
    "import torch\n",
    "vocab_size=len(vocab)\n",
    "# Create a count matrix (vocab_size x vocab_size)\n",
    "N = torch.zeros((vocab_size, vocab_size), dtype=torch.int32)\n",
    "for ch1, ch2 in zip(encoded, encoded[1:]):\n",
    "    N[ch1, ch2] += 1\n",
    "print(\"Bigram count matrix:\\n\", N)\n",
    "\n",
    "\n",
    "# Convert counts → probabilities\n",
    "# Add 1 for smoothing (avoid division by zero)\n",
    "P = (N + 1).float()\n",
    "P /= P.sum(1, keepdim=True)\n",
    "print(\"\\nProbability matrix:\\n\", P)\n",
    "\n",
    "\n",
    "# Generate text using the bigram model\n",
    "import torch\n",
    "# Start with a random character\n",
    "ix = torch.randint(0, vocab_size, (1,)).item()\n",
    "out = [ix]\n",
    "for _ in range(20):  # generate 20 characters\n",
    "    # Sample next char based on probability\n",
    "    probs = P[ix]\n",
    "    ix = torch.multinomial(probs, num_samples=1).item()\n",
    "    out.append(ix)\n",
    "# Decode indices to characters\n",
    "generated_text = ''.join([int_to_char[i] for i in out])\n",
    "print(\"\\nGenerated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Embeddings\n",
    "\n",
    "import torch\n",
    "text_size = len(list(text))\n",
    "embedding_dim = 8\n",
    "# Create token embedding table\n",
    "token_embedding_table = torch.nn.Embedding(text_size, embedding_dim)\n",
    "# Convert encoded list to tensor\n",
    "tokens = torch.tensor(encoded, dtype=torch.long)\n",
    "# Lookup embeddings\n",
    "token_embeds = token_embedding_table(tokens)\n",
    "print(\"\\nToken Embeddings shape:\", token_embeds.shape)\n",
    "print(token_embeds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
